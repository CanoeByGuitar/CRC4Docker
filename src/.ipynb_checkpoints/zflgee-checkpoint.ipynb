{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook examples for ZFL/GEE Course April 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three ways to access and program the GEE\n",
    "\n",
    "### 1. Work entirely in the code editor with the JavaScript API\n",
    "https://code.earthengine.google.com/  \n",
    "\n",
    "### 2. Work with the Python API either locally (Docker) or on the Web (Docker on Google Cloud)\n",
    "#### Official Docker container (datalab):\n",
    "https://developers.google.com/earth-engine/python_install\n",
    "#### This course:\n",
    "https://github.com/mortcanty/CRC4Docker\n",
    "\n",
    "### 3. Publish your own Web Application to make your methods available to anyone\n",
    "http://ms-image-analysis.appspot.com/static/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Python API on a Jupyter Notebook\n",
    "\n",
    "### sudo docker run -d -p 443:8888 --name=crc4 mort/crc4docker\n",
    "### Point your browser to localhost:443\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The command line interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!earthengine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable inline graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the data catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee, time\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "try:\n",
    "    point = ee.Geometry.Point([8.5,50.0]) \n",
    "    start = ee.Date('2016-05-01')\n",
    "    finish = ee.Date('2016-08-01')    \n",
    "    collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "                .filterBounds(point) \\\n",
    "                .filterDate(start, finish) \\\n",
    "                .sort('CLOUD_COVERAGE_ASSESSMENT', True)\n",
    "    count = collection.size().getInfo()\n",
    "    if count==0:\n",
    "        raise ValueError('No images found')   \n",
    "    image = ee.Image(collection.first()) \n",
    "    timestamp = ee.Date(image.get('system:time_start')).getInfo()\n",
    "    timestamp = time.gmtime(int(timestamp['value'])/1000)\n",
    "    timestamp = time.strftime('%c', timestamp) \n",
    "    systemid = image.get('system:id').getInfo()\n",
    "    cloudcover = image.get('CLOUD_COVERAGE_ASSESSMENT').getInfo()\n",
    "    projection = image.select('B2').projection().getInfo()['crs']    \n",
    "    print 'system id: %s'%systemid\n",
    "    print 'acquisition time: %s'%timestamp\n",
    "    print 'cloud cover (percent):%s'%cloudcover\n",
    "    print 'projection: %s'%projection\n",
    "except Exception as e:\n",
    "    print 'An error occurred: %s'%e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLat = 50.06526459341422\n",
    "minLon = 8.477334975832491\n",
    "minLat = 50.01013697421883\n",
    "maxLon = 8.633890151613743\n",
    "rect = ee.Geometry.Rectangle(minLon,minLat,maxLon,maxLat)\n",
    "exportname = 'users/mortcanty/'+systemid.replace('/','-')\n",
    "assexport = ee.batch.Export.image.toAsset(image.clip(rect).select('B2','B3','B4','B8'),\n",
    "                                          description='assetExportTask', \n",
    "                                          assetId=exportname,scale=10,maxPixels=1e9)\n",
    "assexportid = str(assexport.id)\n",
    "print '****Exporting to Assets, task id: %s '%assexportid\n",
    "assexport.start() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ee.List([1,2,3,4])\n",
    "\n",
    "def squareit(x):\n",
    "    x = ee.Number(x)\n",
    "    return x.multiply(x)\n",
    "\n",
    "squaredlist = list.map(squareit)\n",
    "print  squaredlist.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image.reduceRegion example\n",
    "#\n",
    "# Computes a simple reduction over a region of an image.  A reduction\n",
    "# is any process that takes an arbitrary number of inputs (such as\n",
    "# all the pixels of an image in a given region) and computes one or\n",
    "# more fixed outputs.  The result is a dictionary that contains the\n",
    "# computed values, which in this example is the maximum pixel value\n",
    "# in the region.\n",
    "#\n",
    "# This example shows how to print the resulting dictionary to the\n",
    "# console, which is useful when developing and debugging your\n",
    "# scripts, but in a larger workflow you might instead use the\n",
    "# Dicitionary.get() function to extract the values print np.max(band1)you need from the\n",
    "# dictionary for use as inputs to other functions.\n",
    "\n",
    "# The input image to reduce, in this case an SRTM elevation map.\n",
    "image = ee.Image('srtm90_v4')\n",
    "\n",
    "# The region to reduce within.\n",
    "poly = ee.Geometry.Rectangle(-109.05, 41, -102.05, 37)\n",
    "\n",
    "# Reduce the image within the given region, using a reducer that\n",
    "# computes the max pixel value.  We also specify the spatial\n",
    "# resolution at which to perform the computation, in this case 200\n",
    "# meters.\n",
    "max = image.reduceRegion(ee.Reducer.max(), poly, 200)\n",
    "\n",
    "# Print the result to the console.\n",
    "print max.getInfo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Python\n",
    "\n",
    "sum = 0\n",
    "for i in range(10):\n",
    "    sum += i\n",
    "print sum    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "print np.array(range(10)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee Python API\n",
    "\n",
    "def sum(current,prev):\n",
    "    prev = ee.Number(prev)\n",
    "    return prev.add(current)\n",
    "\n",
    "input = ee.List.sequence(0,9)\n",
    "first = ee.Number(0)\n",
    "result = input.iterate(sum,first)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print result.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/api/thumb?thumbid=aa57995a1b185d9e3fc965cd469d8116&token=d82f544b400ab3bb8ad18be9530bbd41\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ee\n",
    "from auxil import eepca\n",
    "import IPython.display as disp\n",
    "ee.Initialize()\n",
    "\n",
    "im = ee.Image(\n",
    "  'LANDSAT/LE07/C01/T1_RT_TOA/LE07_197025_20010626').select('B1','B2','B3','B4','B5','B7')\n",
    "    \n",
    "pcs, lambdas = eepca.pca(im) \n",
    "\n",
    "url = pcs.select('pc1','pc2','pc3').getThumbURL({'min':-0.1,'max':0.1})\n",
    "disp.Image(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdexporttask = ee.batch.Export.image.toDrive(pcs,\n",
    "               description='driveExportTask', \n",
    "               folder='EarthEngineImages',\n",
    "               fileNamePrefix='PCA_20010626',\n",
    "               scale=30,\n",
    "               maxPixels=1e9) \n",
    "gdexporttask.start()              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = ee.Image(\n",
    "  'LANDSAT/LE07/C01/T1_RT_TOA/LE07_197025_20010626') \\\n",
    "       .select('B4')\n",
    "edges = ee.Algorithms.CannyEdgeDetector(im,0.2)\n",
    "\n",
    "gdexporttask = ee.batch.Export.image.toAsset(edges,\n",
    "                      description='assetExportTask', \n",
    "                      assetId='users/mortcanty/edges',\n",
    "                      scale=30,\n",
    "                      maxPixels=1e9) \n",
    "gdexporttask.start()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSV panchromatic sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Landsat 8 top-of-atmosphere reflectance image.\n",
    "image = ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318')\n",
    "\n",
    "# Convert the RGB bands to the HSV color space.\n",
    "hsv = image.select(['B4', 'B3', 'B2']).rgbToHsv()\n",
    "\n",
    "# Swap in the panchromatic band and convert back to RGB.\n",
    "sharpened = ee.Image.cat([\n",
    "  hsv.select('hue'), hsv.select('saturation'), image.select('B8')\n",
    "]).hsvToRgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdexporttask = ee.batch.Export.image.toAsset(sharpened,\n",
    "                      description='assetExportTask', \n",
    "                      assetId='users/mortcanty/pansharpened',\n",
    "                      scale=15,\n",
    "                      maxPixels=1e9) \n",
    "gdexporttask.start()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAR change detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector and matrix representations\n",
    "\n",
    "A fully polarimetric SAR measures a\n",
    "$2\\times 2$ _scattering matrix_ $S$  at each resolution cell on the ground.\n",
    "The scattering matrix relates the incident and the backscattered\n",
    "electric fields $E^i$ and $E^b$ according to\n",
    "\n",
    "$$\n",
    "\\pmatrix{E_h^b \\cr E_v^b}\n",
    "=\\pmatrix{S_{hh} & S_{hv}\\cr S_{vh} & S_{vv}}\\pmatrix{E_h^i \\cr E_v^i}.\n",
    "$$\n",
    "\n",
    "Here $E_h^{i(b)}$ and $E_v^{i(b)}$ denote the horizontal and vertical components of the incident (backscattered)\n",
    "oscillating electric fields directly at the target. These can be deduced from the transmitted and received\n",
    "radar signals via the so-called _far field_ approximations.\n",
    "If both horizontally and vertically polarized radar pulses are\n",
    "emitted and discriminated then they determine, from the above Equation, the four complex scattering matrix elements.\n",
    "The per-pixel polarimetric information in the scattering matrix $S$, under the assumption\n",
    "of reciprocity ($S_{hv} = S_{vh}$), can then be expressed as a three-component complex vector\n",
    "\n",
    "$$\n",
    "s = \\pmatrix{S_{hh}\\cr \\sqrt{2}S_{hv}\\cr S_{vv}},\n",
    "$$\n",
    "\n",
    "\n",
    "where the $\\sqrt{2}$ ensures that the total intensity (received signal power) is consistent. It is essentially these vectors which are provided in the SLC level one data discussed above. The total intensity is referred to as the _span_ and is the complex inner product of the vector $s$,\n",
    "\n",
    "$$\n",
    "{\\rm span} = s^\\top s = |S_{hh}|^2 + 2|S_{hv}|^2 + |S_{vv}|^2.\n",
    "$$\n",
    "\n",
    "This is a real number and the corresponding gray-scale image is called the _span image_. The observation vector $s$ can be shown to be a realization of a complex multivariate normal random variable. An equivalent and often preferred representation is in terms of the *coherency vector* or *Pauli decomposition*\n",
    "\n",
    "$$\n",
    "k = {1\\over\\sqrt{2}}\\pmatrix{S_{hh} + S_{vv}\\cr S_{hh} - S_{vv} \\cr 2S_{hv}}.\n",
    "$$\n",
    "\n",
    "The polarimetric signal is  can also be represented by taking the complex outer product of $s$ with itself:\n",
    "\n",
    "$$\n",
    "C = s s^\\top = \\pmatrix{ |S_{hh}|^2 & \\sqrt{2}S_{hh}S_{hv}^* & S_{hh}S_{vv}^* \\cr\n",
    "                                     \\sqrt{2}S_{hv}S_{hh}^* & 2|S_{hv}|^2 & \\sqrt{2}S_{hv}S_{vv}^* \\cr\n",
    "                                     S_{vv}S_{hh}^* & \\sqrt{2}S_{vv}S_{hv}^* & |S_{vv}|^2 }.\n",
    "$$\n",
    "\n",
    "The diagonal elements of $C$ are real numbers, with span $= {\\rm tr}(C)$, and the off-diagonal\n",
    "elements are complex. This matrix representation contains all of the information in the polarized signal.\n",
    "\n",
    "\n",
    "\n",
    "#### Multi-looking\n",
    "\n",
    "The matrix $C$ can be averaged over the number of looks (number of adjacent cells used to average out the effect of speckle) to give an estimate of the __covariance matrix__ of each multi-look pixel:\n",
    "\n",
    "$$\n",
    "\\bar{C}  ={1\\over m}\\sum_{\\nu=1}^m  s(\\nu) s(\\nu)^\\top = \\langle  s s^\\top \\rangle\n",
    " = \\pmatrix{ \\langle |S_{hh}|^2\\rangle & \\langle\\sqrt{2}S_{hh}S_{hv}^*\\rangle & \\langle S_{hh}S_{vv}^*\\rangle \\cr\n",
    "\\langle\\sqrt{2} S_{hv}S_{hh}^*\\rangle & \\langle 2|S_{hv}|^2\\rangle & \\langle\\sqrt{2}S_{hv}S_{vv}^*\\rangle \\cr\n",
    "\\langle S_{vv}S_{hh}^*\\rangle & \\langle\\sqrt{2}S_{vv}S_{hv}^*\\rangle & \\langle |S_{vv}|^2\\rangle },\n",
    "$$\n",
    "\n",
    "where $m$ is the number of looks. This matrix (or alternatively the equivalent __coherency matrix__ $\\langle  k k^\\top \\rangle$) can be generated with the Sentinel-1 Toolbox.  Rewriting the first of the above equalities,\n",
    "\n",
    "$$\n",
    "m\\bar{C} = \\sum_{\\nu=1}^m  s(\\nu) s(\\nu)^\\top =:  x.\n",
    "$$\n",
    "\n",
    "This quantity $x$ is a realization of a __complex random matrix__ which is known to have\n",
    "a complex Wishart distribution with $N\\times N$ covariance matrix $\\Sigma$ (here $N=3$) and $m$ degrees of freedom:\n",
    "\n",
    "$$\n",
    "p_{W_c}( x) ={|x|^{(m-N)}\\exp(-{\\rm tr}(\\Sigma^{-1} x)) \\over\n",
    "\\pi^{N(N-1)/2}|\\Sigma|^{m}\\prod_{i=1}^N\\Gamma(m+1-i)},\\quad m \\ge N,\n",
    "$$\n",
    "\n",
    "provided that the vectors $s(\\nu)$ are independent and drawn from a complex multivariate normal distribution.\n",
    "\n",
    "#### Dual and single polarimetric imagery\n",
    "\n",
    "The scattering vector given above corresponds to so-called full, or _quad polarimetric_ SAR.\n",
    "Satellite-based SAR sensors often operate in reduced, power-saving polarization modes, emitting only one polarization and receiving\n",
    "two (dual polarization) or one (single polarization). The look-averaged covariance matrices are reduced in dimension\n",
    "correspondingly. For instance for dual polarization with horizontal transmission and horizontal and vertical reception,\n",
    "\n",
    "$$\n",
    "\\bar{C} = \\pmatrix{ \\langle |S_{hh}|^2\\rangle & \\langle S_{hh}S_{hv}^*\\rangle \\cr\n",
    "\\langle S_{hv}S_{hh}^*\\rangle & \\langle |S_{hv}|^2\\rangle },\n",
    "$$\n",
    "\n",
    "and, for single polarization and horizontal transmission/reception, we get simply the intensity image\n",
    "\n",
    "$$\n",
    "\\bar{I} = \\langle |S_{hh}|^2\\rangle \\quad {\\rm or} \\quad \\bar{I} = \\langle |S_{vv}|^2\\rangle.\n",
    "$$\n",
    "\n",
    "A special case, relevant to Sentinel-1 data on the GEE is vertical transmission, vertical and horizontal reception without including the off diagonal complex element:\n",
    "\n",
    "$$\n",
    "\\bar{C} = \\pmatrix{ \\langle |S_{vv}|^2\\rangle & 0 \\cr\n",
    " 0 & \\langle |S_{vh}|^2\\rangle }\n",
    "$$\n",
    "\n",
    "referred to as dualpol, diagonal only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-temporal data: the omnibus test\n",
    "\n",
    "The following is discussion is based on <a href=\"http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=1219\">Conradsen et al (2003)</a>.\n",
    "\n",
    "As we have seen, we can represent a pixel vector in an $m$ look-averaged\n",
    "polSAR image in covariance matrix format by $\\bar C$, where\n",
    "\n",
    "$$\n",
    "m\\bar C =  x = \\sum_{\\nu=1}^m  s(\\nu) s(\\nu)^\\top\n",
    "$$\n",
    "\n",
    "is a realization of a random matrix $X$ with a complex Wishart distribution.\n",
    "\n",
    "In order to derive a change detection procedure for two polarimetric SAR images, we formulate a statistical test. For each pixel in $k$ images, define the null (or no-change) simple  hypothesis as\n",
    "\n",
    "$$\n",
    "H_0:\\quad \\Sigma_1 = \\Sigma_2 = \\dots = \\Sigma_k = \\Sigma,\n",
    "$$\n",
    "\n",
    "and the alternative composite hypothesis as\n",
    "\n",
    "$$\n",
    "H_1:\\quad \\Sigma_i \\ne \\Sigma_j \n",
    "$$\n",
    "for at least one pair $i,j$\n",
    "\n",
    "Then the __likelihood ratio test__ has the critical region for rejection of the no-change hypothesis\n",
    "\n",
    "$$\n",
    "Q = k^{kNm}{ |x_1|^m |x_2|^m\\cdots |x_k|^m \\over |x_1 + x_2 + \\dots x_k|^{km} } \\le t\n",
    "$$\n",
    "\n",
    "where $t$ is some small number and $N$ is the dimension of $x$.\n",
    "\n",
    "Taking logarithms:\n",
    "\n",
    "$$\n",
    "\\ln Q = m(Nk\\ln k + \\sum_{i=1}^k \\ln|x_i| - k \\ln|x|) \\le t'\n",
    "$$\n",
    "\n",
    "where $x = \\sum_{i=1}^k x_i$.\n",
    "\n",
    "Finally, we have the following approximation for the statistical distribution of the test statistic $Q$:\n",
    "\n",
    "$$\n",
    "{\\rm prob}(-2\\log Q\\le z) \\simeq P_{\\chi^2;(k-1)f}(z)\n",
    "$$\n",
    "\n",
    "where $f$ is the number of parameters requred to specify $x$: 9 for quadpol, 4 for dualpol and 2 for dualpol diagonal only.\n",
    "\n",
    "In practice we choose a significance level $\\alpha$, e.g., $\\alpha = 0.01$, and decision threshold $z$ such that\n",
    "\n",
    "$$\n",
    "{\\rm prob}(-2\\log Q\\le z) = 1-\\alpha\n",
    "$$\n",
    "\n",
    "and interpret all pixels with larger values of $-2\\rho\\log Q$ as change.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sequential omnibus test\n",
    "\n",
    "Furthermore this test can be factored into a sequence of  tests involving hypotheses of the form\n",
    "$\\Sigma_1 = \\Sigma_2$ against $\\Sigma_1 \\ne \\Sigma_2$,\n",
    "$\\Sigma_1 = \\Sigma_2 = \\Sigma_3$ against $\\Sigma_1 = \\Sigma_2 \\ne \\Sigma_3$, and so forth. For example, to test\n",
    "\n",
    "$$\n",
    "H_{0j}: \\quad \\Sigma_1 = \\Sigma_2 = \\dots \\Sigma_{j-1} = \\Sigma_j\n",
    "$$\n",
    "\n",
    "against\n",
    "\n",
    "$$\n",
    "H_{0j}: \\quad \\Sigma_1 = \\Sigma_2 = \\dots \\Sigma_{j-1} \\ne \\Sigma_j\n",
    "$$\n",
    "\n",
    "the likelihood ratio test statstic is $R^1_j$ given by\n",
    "\n",
    "$$\n",
    "\\ln R^1_j = m\\big[N(j\\ln j - (j-1)\\ln (j-1)) + (j-1)\\ln \\big|\\sum_{i=1}^{j-1} x_i\\big| + \\ln|x_j| - j\\ln \\big|\\sum_{i=1}^{j} x_i\\big|\\ \\big] \\quad j=2\\dots k.\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "{\\rm prob}(-2\\log R^1_j\\le z) \\simeq P_{\\chi^2;f}(z)\n",
    "$$\n",
    "\n",
    "Now suppose that we conclude $\\Sigma_1\\ne \\Sigma_2$. Then we can continue to look for additional changes by restarting the tests at $j=2$,\n",
    "\n",
    "$$\n",
    "\\ln R^2_j = m\\big[N(j\\ln j - (j-1)\\ln (j-1)) + (j-1)\\ln \\big|\\sum_{i=2}^{j-1} x_i\\big| + \\ln|x_j| - j\\ln \\big|\\sum_{i=2}^{j} x_i\\big|\\ \\big] \\quad j=3\\dots k.\n",
    "$$\n",
    "\n",
    "For a series of, say, 5 images we therefore have, __for each pixel__, the following tests to consider\n",
    "\n",
    "$$\n",
    "\\matrix{\n",
    "R^1_2 & R^1_3 & R^1_4 & R^1_5 \\cr\n",
    "      & R^2_3 & R^2_4 & R^2_5 \\cr\n",
    "      &       & R^3_4 & R^3_5 \\cr\n",
    "      &       &       & R^4_5 }\n",
    "$$      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = ee.Geometry.Rectangle( [5.9985351562500009, 50.938486572440667, 6.0946655273437509, 50.973953836311068])\n",
    "collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "                        .filterBounds(rect) \\\n",
    "                        .filterDate(ee.Date('2016-04-01'), ee.Date('2016-09-01')) \\\n",
    "                        .filter(ee.Filter.eq('transmitterReceiverPolarisation', ['VV','VH'])) \\\n",
    "                        .filter(ee.Filter.eq('resolution_meters', 10)) \\\n",
    "                        .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "                        .filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING')) \\\n",
    "                        .sort('system:time_start')                                     \n",
    "acquisition_times = ee.List(collection.aggregate_array('system:time_start')).getInfo() \n",
    "count = len(acquisition_times)\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxil import eeWishart\n",
    "import math\n",
    "\n",
    "def get_vvvh(image):   \n",
    "    ''' get 'VV' and 'VH' bands from sentinel-1 imageCollection and restore linear signal from db-values '''\n",
    "    return image.select('VV','VH').multiply(ee.Image.constant(math.log(10.0)/10.0)).exp()\n",
    "\n",
    "def clipList(current,prev):\n",
    "    ''' clip a list of images '''\n",
    "    imlist = ee.List(ee.Dictionary(prev).get('imlist'))\n",
    "    rect = ee.Dictionary(prev).get('rect')    \n",
    "    imlist = imlist.add(ee.Image(current).clip(rect))\n",
    "    return ee.Dictionary({'imlist':imlist,'rect':rect})\n",
    "\n",
    "pcollection = collection.map(get_vvvh)\n",
    "\n",
    "# get the list of images and clip to roi\n",
    "pList = pcollection.toList(count)   \n",
    "first = ee.Dictionary({'imlist':ee.List([]),'rect':rect}) \n",
    "imList = ee.Dictionary(pList.iterate(clipList,first)).get('imlist')  \n",
    "\n",
    "# run the algorithm ------------------------------------------   \n",
    "result = ee.Dictionary(eeWishart.omnibus(imList,0.0001,True))\n",
    "# ------------------------------------------------------------      \n",
    "\n",
    "cmap = ee.Image(result.get('cmap')).byte()   \n",
    "smap = ee.Image(result.get('smap')).byte()\n",
    "fmap = ee.Image(result.get('fmap')).byte()  \n",
    "bmap = ee.Image(result.get('bmap')).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet = 'black,blue,cyan,yellow,red'\n",
    "url = fmap.getThumbURL({'min':0,'max':5,'palette':jet})\n",
    "disp.Image(url=url,width = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background image for video generation                    \n",
    "collection1 = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "                            .filterBounds(rect) \\\n",
    "                            .filterDate(ee.Date('2016-04-01'), ee.Date('2016-09-01')) \\\n",
    "                            .sort('CLOUDY_PIXEL_PERCENTAGE',True)                \n",
    "background = ee.Image(collection1.first()) \\\n",
    "                           .clip(rect) \\\n",
    "                           .select('B8') \\\n",
    "                           .divide(10000)                      \n",
    "# export\n",
    "bnames = bmap.bandNames().getInfo()\n",
    "\n",
    "cmaps = ee.Image.cat(cmap,smap,fmap,bmap,background) \\\n",
    "                .rename(['cmap','smap','fmap']+bnames+['background']) \n",
    "\n",
    "assexport = ee.batch.Export.image.toAsset(cmaps,\n",
    "                description='assetExportTask', \n",
    "                assetId='users/mortcanty/omnibus_change_maps',scale=10,maxPixels=1e9)\n",
    "assexportid = str(assexport.id)\n",
    "print '****Exporting to Assets, task id: %s '%assexportid\n",
    "assexport.start() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/dispms -f imagery/may0107pca.tif -p [1,2,3] -e 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 4 principal components of ASTER image\n",
    "image = ee.Image('users/mortcanty/supervisedclassification/may0107pca') \\\n",
    "            .select(0,1,2,3)\n",
    "\n",
    "# training data\n",
    "table = ee.FeatureCollection('users/mortcanty/supervisedclassification/train')\n",
    "trainData = image.sampleRegions(table,['CLASS_ID'])\n",
    "print trainData.size().getInfo()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jmsep(class1,class2,image,table):\n",
    "# Jeffries-Matusita separability    \n",
    "    table1 = table.filter(\n",
    "        ee.Filter.eq('CLASS_ID',str(class1-1)))\n",
    "    m1 = image.reduceRegion(ee.Reducer.mean(),table1)\\\n",
    "              .toArray() \n",
    "    s1 = image.toArray() \\\n",
    "         .reduceRegion(ee.Reducer.covariance(),table1)\\\n",
    "         .toArray()\n",
    "    table2 = table.filter(\n",
    "        ee.Filter.eq('CLASS_ID',str(class2-1)))\n",
    "    m2 = image.reduceRegion(ee.Reducer.mean(),table2)\\\n",
    "              .toArray()\n",
    "    s2 = image.toArray() \\\n",
    "        .reduceRegion(ee.Reducer.covariance(),table2,15)\\\n",
    "              .toArray()\n",
    "    m12 = m1.subtract(m2)  \n",
    "    m12 = ee.Array([m12.toList()]) # makes 2D matrix  \n",
    "    s12i = s1.add(s2).divide(2).matrixInverse()\n",
    "#  first term in Bhattacharyya distance\n",
    "    B1 = m12.matrixMultiply(\n",
    "          s12i.matrixMultiply(m12.matrixTranspose())) \\\n",
    "            .divide(8)\n",
    "    ds1 = s1.matrixDeterminant()\n",
    "    ds2 = s2.matrixDeterminant() \n",
    "    ds12 = s1.add(s2).matrixDeterminant()\n",
    "#  second term\n",
    "    B2 = ds12.divide(2).divide(ds1.multiply(ds2).sqrt())\\\n",
    "             .log().divide(2)\n",
    "    B = ee.Number(B1.add(B2).project([0]).toList().get(0))\n",
    "#  J-M separability\n",
    "    return ee.Number(1).subtract(ee.Number(1) \\\n",
    "             .divide(B.exp())) \\\n",
    "             .multiply(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print jmsep(5,9,image,table).getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as disp\n",
    "jet = 'black,blue,cyan,yellow,red,brown'\n",
    "\n",
    "# rename the class ids from strings to integers\n",
    "trainData = image.sampleRegions(table,['CLASS_ID'])\\\n",
    "    .remap(['0','1','2','3','4','5','6','7','8','9'],\n",
    "           [0,1,2,3,4,5,6,7,8,9],'CLASS_ID')\n",
    "    \n",
    "# train a naive Bayes classifier    \n",
    "classifier = ee.Classifier.continuousNaiveBayes()\n",
    "trained = classifier.\\\n",
    "    train(trainData,'CLASS_ID',image.bandNames())\n",
    "\n",
    "# classify the image and display    \n",
    "classified = image.classify(trained)\n",
    "url = classified.select('classification').\\\n",
    "    getThumbURL({'min':0,'max':9,'palette':jet})\n",
    "disp.Image(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
